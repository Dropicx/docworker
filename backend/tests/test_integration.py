"""
Integration Tests for DocTranslator

Tests component interactions and end-to-end workflows.
Uses in-memory SQLite database for fast, isolated testing.
"""

import pytest
import os
import sys
from unittest.mock import Mock, patch, AsyncMock
from io import BytesIO
from PIL import Image
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

from app.database.modular_pipeline_models import (
    DynamicPipelineStepDB,
    AvailableModelDB,
    DocumentClassDB,
    PipelineJobDB,
    Base,
    StepExecutionStatus,
)
from app.services.document_class_manager import DocumentClassManager
from app.services.modular_pipeline_executor import ModularPipelineExecutor
from app.services.file_validator import FileValidator


@pytest.fixture(scope="function")
def db_session():
    """Create an in-memory SQLite database session for testing"""
    # Create in-memory database
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)

    # Create session
    SessionLocal = sessionmaker(bind=engine)
    session = SessionLocal()

    yield session

    # Cleanup
    session.close()
    Base.metadata.drop_all(engine)


@pytest.fixture
def seed_document_classes(db_session):
    """Seed database with system document classes"""
    classes = [
        DocumentClassDB(
            class_key="ARZTBRIEF",
            display_name="Arztbrief",
            description="Doctor's letters, discharge summaries",
            icon="ðŸ“„",
            is_enabled=True,
            is_system_class=True,
            strong_indicators=["Arztbrief", "Entlassungsbrief"],
            weak_indicators=["Klinik", "Station"],
        ),
        DocumentClassDB(
            class_key="BEFUNDBERICHT",
            display_name="Befundbericht",
            description="Medical findings and diagnostic reports",
            icon="ðŸ”¬",
            is_enabled=True,
            is_system_class=True,
            strong_indicators=["Befund", "Diagnose"],
            weak_indicators=["Untersuchung"],
        ),
        DocumentClassDB(
            class_key="LABORWERTE",
            display_name="Laborwerte",
            description="Lab results and blood tests",
            icon="ðŸ§ª",
            is_enabled=True,
            is_system_class=True,
            strong_indicators=["Labor", "Blutwerte"],
            weak_indicators=["mg/dl", "Referenzbereich"],
        ),
    ]

    for doc_class in classes:
        db_session.add(doc_class)

    db_session.commit()
    return classes


@pytest.fixture
def seed_models(db_session):
    """Seed database with available AI models"""
    models = [
        AvailableModelDB(
            name="Meta-Llama-3_3-70B-Instruct",
            display_name="Llama 3.3 70B",
            provider="OVH",
            max_tokens=8192,
            price_input_per_1m_tokens=0.1,  # $0.10 per 1M input tokens
            price_output_per_1m_tokens=0.2,  # $0.20 per 1M output tokens
            is_enabled=True,
            supports_vision=False,
        ),
        AvailableModelDB(
            name="Mistral-Nemo-Instruct-2407",
            display_name="Mistral Nemo",
            provider="OVH",
            max_tokens=4096,
            price_input_per_1m_tokens=0.05,  # $0.05 per 1M input tokens
            price_output_per_1m_tokens=0.1,  # $0.10 per 1M output tokens
            is_enabled=True,
            supports_vision=False,
        ),
    ]

    for model in models:
        db_session.add(model)

    db_session.commit()
    return models


@pytest.fixture
def seed_pipeline_steps(db_session, seed_models):
    """Seed database with pipeline steps"""
    steps = [
        DynamicPipelineStepDB(
            name="Medical Content Validation",
            order=1,
            prompt_template="Validate if medical: {input_text}",
            selected_model_id=seed_models[1].id,  # Mistral
            temperature=0.3,
            max_tokens=100,
            enabled=True,
            input_from_previous_step=True,
            retry_on_failure=False,
            document_class_id=None,
            post_branching=False,
            is_branching_step=False,
        ),
        DynamicPipelineStepDB(
            name="Document Classification",
            order=2,
            prompt_template="Classify document: {input_text}",
            selected_model_id=seed_models[0].id,  # Llama
            temperature=0.3,
            max_tokens=50,
            enabled=True,
            input_from_previous_step=True,
            retry_on_failure=False,
            document_class_id=None,
            post_branching=False,
            is_branching_step=True,
            branching_field="document_type",
        ),
        DynamicPipelineStepDB(
            name="Language Translation",
            order=10,
            prompt_template="Translate to {target_language}: {input_text}",
            selected_model_id=seed_models[0].id,
            temperature=0.7,
            max_tokens=4096,
            enabled=True,
            input_from_previous_step=True,
            retry_on_failure=True,
            max_retries=3,
            document_class_id=None,
            post_branching=True,
            required_context_variables=["target_language"],
            is_branching_step=False,
        ),
    ]

    for step in steps:
        db_session.add(step)

    db_session.commit()
    return steps


class TestDocumentClassManagerIntegration:
    """Integration tests for DocumentClassManager with database"""

    def test_crud_lifecycle(self, db_session, seed_document_classes):
        """Test complete CRUD lifecycle for document classes"""
        manager = DocumentClassManager(session=db_session)

        # CREATE
        new_class = manager.create_class(
            {
                "class_key": "THERAPIEPLAN",
                "display_name": "Therapieplan",
                "description": "Treatment plans",
                "icon": "ðŸ’Š",
                "is_enabled": True,
                "is_system_class": False,
                "strong_indicators": ["Therapie", "Behandlungsplan"],
                "weak_indicators": ["Medikation"],
            }
        )

        assert new_class is not None
        assert new_class.class_key == "THERAPIEPLAN"

        # READ
        retrieved = manager.get_class_by_key("THERAPIEPLAN")
        assert retrieved is not None
        assert retrieved.id == new_class.id

        # UPDATE
        updated = manager.update_class(
            new_class.id, {"description": "Comprehensive therapy and treatment plans"}
        )
        assert updated.description == "Comprehensive therapy and treatment plans"

        # DELETE (should work for non-system class)
        success = manager.delete_class(new_class.id)
        assert success is True

        # Verify deletion
        deleted = manager.get_class_by_key("THERAPIEPLAN")
        assert deleted is None

    def test_system_class_protection(self, db_session, seed_document_classes):
        """Test that system classes cannot be deleted"""
        manager = DocumentClassManager(session=db_session)

        arztbrief = manager.get_class_by_key("ARZTBRIEF")

        # Should raise error when trying to delete system class
        with pytest.raises(ValueError, match="Cannot delete system document class"):
            manager.delete_class(arztbrief.id)

    def test_get_classification_prompt(self, db_session, seed_document_classes):
        """Test classification prompt generation"""
        manager = DocumentClassManager(session=db_session)

        prompt = manager.get_classification_prompt_template()

        assert "ARZTBRIEF" in prompt
        assert "BEFUNDBERICHT" in prompt
        assert "LABORWERTE" in prompt
        assert "{input_text}" in prompt

    def test_enabled_classes_only(self, db_session, seed_document_classes):
        """Test filtering by enabled classes"""
        manager = DocumentClassManager(session=db_session)

        # Disable one class
        arztbrief = manager.get_class_by_key("ARZTBRIEF")
        manager.update_class(arztbrief.id, {"is_enabled": False})

        # Get enabled classes
        enabled = manager.get_enabled_classes()

        assert len(enabled) == 2  # Only 2 enabled now
        assert all(cls.is_enabled for cls in enabled)


class TestModularPipelineExecutorIntegration:
    """Integration tests for ModularPipelineExecutor with database"""

    def test_load_pipeline_configuration(self, db_session, seed_pipeline_steps, seed_models):
        """Test loading complete pipeline configuration"""
        executor = ModularPipelineExecutor(session=db_session)

        # Load all steps
        steps = executor.load_pipeline_steps()
        assert len(steps) == 3

        # Load universal steps (pre-branching)
        universal = executor.load_universal_steps()
        assert len(universal) == 2  # Medical Validation + Classification

        # Load post-branching steps
        post_branching = executor.load_post_branching_steps()
        assert len(post_branching) == 1  # Translation

    def test_find_branching_step(self, db_session, seed_pipeline_steps):
        """Test finding branching step in loaded pipeline"""
        executor = ModularPipelineExecutor(session=db_session)

        steps = executor.load_pipeline_steps()
        branching_step = executor.find_branching_step(steps)

        assert branching_step is not None
        assert branching_step.name == "Document Classification"
        assert branching_step.is_branching_step is True

    def test_model_selection(self, db_session, seed_models, seed_pipeline_steps):
        """Test model selection for pipeline steps"""
        executor = ModularPipelineExecutor(session=db_session)

        steps = executor.load_pipeline_steps()

        # Check that models are correctly assigned
        for step in steps:
            model = executor.get_model_info(step.selected_model_id)
            assert model is not None
            assert model.is_enabled is True


class TestFileValidationIntegration:
    """Integration tests for file validation"""

    @pytest.mark.asyncio
    async def test_validate_pdf_file(self):
        """Test PDF file validation"""
        # Create a minimal PDF-like file
        pdf_content = b"%PDF-1.4\n1 0 obj\n<<>>\nendobj\nxref\n0 1\ntrailer\n<<>>\n%%EOF"

        from fastapi import UploadFile
        from io import BytesIO

        upload_file = UploadFile(
            filename="test.pdf",
            file=BytesIO(pdf_content),
            headers={"content-type": "application/pdf"},
        )

        is_valid, error = await FileValidator.validate_file(upload_file)

        # Note: May fail without proper PDF structure, but tests the flow
        # The important thing is it doesn't crash

    @pytest.mark.asyncio
    async def test_validate_image_file(self):
        """Test image file validation"""
        # Create a small test image (300x300 to be well above minimums)
        img = Image.new("RGB", (300, 300), color="white")
        img_byte_arr = BytesIO()
        img.save(img_byte_arr, format="PNG")
        img_content = img_byte_arr.getvalue()

        from fastapi import UploadFile

        upload_file = UploadFile(
            filename="test.png", file=BytesIO(img_content), headers={"content-type": "image/png"}
        )

        is_valid, error = await FileValidator.validate_file(upload_file)

        # Note: May fail without proper dependencies (python-magic), but tests the flow
        # The important thing is it doesn't crash
        if not is_valid:
            # Validation failed but didn't crash - acceptable for integration test
            assert error is not None

    def test_get_file_type(self):
        """Test file type detection"""
        assert FileValidator.get_file_type("document.pdf") == "pdf"
        assert FileValidator.get_file_type("scan.jpg") == "image"
        assert FileValidator.get_file_type("photo.PNG") == "image"
        assert FileValidator.get_file_type("file.jpeg") == "image"


class TestPipelineJobWorkflow:
    """Integration tests for complete pipeline job workflow"""

    def test_create_and_track_job(self, db_session, seed_models, seed_pipeline_steps):
        """Test creating and tracking a pipeline job"""
        import uuid

        # Create a job
        job = PipelineJobDB(
            job_id=str(uuid.uuid4()),
            processing_id=str(uuid.uuid4()),
            filename="test_document.pdf",
            file_type="pdf",
            file_size=12345,
            file_content=b"fake pdf content",
            client_ip="127.0.0.1",
            status=StepExecutionStatus.PENDING,
            progress_percent=0,
            pipeline_config={"steps": []},
            ocr_config={"selected_engine": "PADDLEOCR"},
        )

        db_session.add(job)
        db_session.commit()

        # Retrieve and verify
        retrieved = (
            db_session.query(PipelineJobDB).filter_by(processing_id=job.processing_id).first()
        )

        assert retrieved is not None
        assert retrieved.status == StepExecutionStatus.PENDING
        assert retrieved.progress_percent == 0

        # Update progress
        retrieved.progress_percent = 50
        retrieved.status = StepExecutionStatus.RUNNING
        db_session.commit()

        # Verify update
        updated = db_session.query(PipelineJobDB).filter_by(processing_id=job.processing_id).first()
        assert updated.progress_percent == 50
        assert updated.status == StepExecutionStatus.RUNNING


class TestDatabaseConstraints:
    """Integration tests for database constraints and relationships"""

    def test_unique_document_class_key(self, db_session):
        """Test that document class keys must be unique"""
        manager = DocumentClassManager(session=db_session)

        # Create first class
        manager.create_class(
            {
                "class_key": "UNIQUE_KEY",
                "display_name": "Test Class",
                "description": "Test",
                "icon": "ðŸ“„",
                "is_enabled": True,
            }
        )

        # Try to create duplicate - should raise error
        with pytest.raises(ValueError, match="already exists"):
            manager.create_class(
                {
                    "class_key": "UNIQUE_KEY",
                    "display_name": "Duplicate",
                    "description": "Test",
                    "icon": "ðŸ“„",
                    "is_enabled": True,
                }
            )

    def test_pipeline_step_ordering(self, db_session, seed_models):
        """Test that pipeline steps maintain order"""
        step1 = DynamicPipelineStepDB(
            name="First Step",
            order=1,
            prompt_template="Test",
            selected_model_id=seed_models[0].id,
            enabled=True,
        )
        step2 = DynamicPipelineStepDB(
            name="Second Step",
            order=2,
            prompt_template="Test",
            selected_model_id=seed_models[0].id,
            enabled=True,
        )
        step3 = DynamicPipelineStepDB(
            name="Third Step",
            order=3,
            prompt_template="Test",
            selected_model_id=seed_models[0].id,
            enabled=True,
        )

        db_session.add_all([step3, step1, step2])  # Add out of order
        db_session.commit()

        # Query and verify correct ordering
        steps = db_session.query(DynamicPipelineStepDB).order_by(DynamicPipelineStepDB.order).all()

        assert len(steps) == 3
        assert steps[0].name == "First Step"
        assert steps[1].name == "Second Step"
        assert steps[2].name == "Third Step"


if __name__ == "__main__":
    # Run tests with verbose output
    pytest.main([__file__, "-v", "--asyncio-mode=auto"])
