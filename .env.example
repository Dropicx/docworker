# ==========================================
# Medical Document Translator - Environment Configuration
# ==========================================

# ==========================================
# Database Configuration
# ==========================================
POSTGRES_USER=doctranslator
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=doctranslator
DATABASE_URL=postgresql://doctranslator:your_secure_password_here@postgres:5432/doctranslator

# ==========================================
# Redis Configuration (Task Queue)
# ==========================================
REDIS_URL=redis://redis:6379/0

# ==========================================
# Worker Configuration
# ==========================================
USE_WORKER_SERVICE=true
WORKER_CONCURRENCY=2
WORKER_MAX_TASKS_PER_CHILD=50
TASK_TIME_LIMIT=600
TASK_SOFT_TIME_LIMIT=540

# ==========================================
# PaddleOCR Service Configuration
# ==========================================
# For Railway Production: Use Railway internal networking (recommended)
# Option 1: Let Railway resolve the internal domain automatically
PADDLEOCR_SERVICE_URL=http://paddleocr-service.railway.internal:9123

# Option 2: Use Railway service reference variables (set this in Railway dashboard)
# PADDLEOCR_SERVICE_URL=http://${{paddleocr-service.RAILWAY_PRIVATE_DOMAIN}}:${{paddleocr-service.PORT}}

# Option 3: Or just domain and port separately
# PADDLEOCR_SERVICE_URL=${{paddleocr-service.RAILWAY_PRIVATE_DOMAIN}}:${{paddleocr-service.PORT}}
# (The normalization function will add http:// automatically)

# For Testing: Use public URL (temporary, for debugging only)
# PADDLEOCR_SERVICE_URL=https://paddleocr-service-dev.up.railway.app

# For Docker Compose: Use service name
# PADDLEOCR_SERVICE_URL=http://paddleocr:9123

# ==========================================
# OVH AI Endpoints Configuration
# ==========================================
OVH_AI_ENDPOINTS_ACCESS_TOKEN=your_ovh_token_here
OVH_AI_BASE_URL=https://llama-3-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1
OVH_MAIN_MODEL=Meta-Llama-3_3-70B-Instruct
OVH_PREPROCESSING_MODEL=Mistral-Nemo-Instruct-2407
OVH_TRANSLATION_MODEL=Meta-Llama-3_3-70B-Instruct

# ==========================================
# Application Configuration
# ==========================================
ENVIRONMENT=development
PORT=9122

# ==========================================
# Railway-Specific Configuration (Production)
# ==========================================
# These are auto-populated by Railway in production
# RAILWAY_ENVIRONMENT=production
# RAILWAY_DOCKERFILE_PATH=dockerfiles/Dockerfile.backend (or frontend/worker)
# DATABASE_URL=postgresql://... (auto from Railway PostgreSQL)
# REDIS_URL=redis://... (auto from Railway Redis)

# ==========================================
# Frontend Configuration
# ==========================================
VITE_API_URL=/api
NODE_ENV=development
